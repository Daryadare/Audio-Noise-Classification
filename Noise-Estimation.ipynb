{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.28.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (67.6.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
      "  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-gc__ou7u\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-gc__ou7u\n",
      "  Resolved https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to commit 6b5e8953a80aef5b324104dc0c2e9b8c34d622bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T12:18:30.759697600Z",
     "start_time": "2023-07-21T12:18:26.611326600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torchaudio.transforms import AmplitudeToDB, Vol\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:29:57.808377200Z",
     "start_time": "2023-07-21T10:29:53.438631300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdarya-dare\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T12:18:34.545339Z",
     "start_time": "2023-07-21T12:18:34.525573800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path_speech, path_noise, eps_value=1e-6,\\\n",
    "                 mel_nframes=300, sample_rate=16000, n_fft=480,\\\n",
    "                 hop_length=160, n_mels=40):\n",
    "\n",
    "        self.speech = pd.read_csv(path_speech)\n",
    "        self.noise = pd.read_csv(path_noise)\n",
    "        self.eps_value = eps_value\n",
    "        self.mel_nframes = mel_nframes\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.mel_spectrogram = T.MelSpectrogram(sample_rate=self.sample_rate,\n",
    "                                                n_fft=self.n_fft,\n",
    "                                                hop_length=self.hop_length,\n",
    "                                                center=True,\n",
    "                                                pad_mode=\"reflect\",\n",
    "                                                power=2.0,\n",
    "                                                norm='slaney',\n",
    "                                                n_mels=self.n_mels)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.noise)\n",
    "\n",
    "    def get_same_shape(self, waveform, w_type):\n",
    "\n",
    "        melsp = torch.log(self.mel_spectrogram(waveform) + self.eps_value)\n",
    "        has_mel_nframes = melsp.size(2) if melsp.size(2) < self.mel_nframes\\\n",
    "         else self.mel_nframes\n",
    "\n",
    "        image_tens = torch.full((1, self.n_mels, self.mel_nframes), melsp.min())\n",
    "        image_tens[0, :, :has_mel_nframes] = melsp[:, :, :has_mel_nframes]\n",
    "\n",
    "        return image_tens\n",
    "\n",
    "    def load_item(self, df, idx, w_type):\n",
    "\n",
    "        sample_wav_file = df['filename'][idx]\n",
    "        wave, _ = torchaudio.load(sample_wav_file)\n",
    "        wave = wave.float()\n",
    "\n",
    "        if w_type==1:\n",
    "            wave_noise = wave.numpy()\n",
    "            wave_noise_no_silence = [float(el) for el in wave_noise[0] if abs(el) >= 0.001]\n",
    "            wave = torch.tensor([wave_noise_no_silence])\n",
    "\n",
    "        wave_melsp = self.get_same_shape(wave, w_type)\n",
    "\n",
    "        return wave_melsp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        wave_speech = self.load_item(self.speech, idx, w_type=0)\n",
    "\n",
    "        luck = random.random()\n",
    "        if luck > 0.5:\n",
    "            wave_noise = self.load_item(self.noise, idx, w_type=1)\n",
    "\n",
    "            wave_out = wave_speech + wave_noise\n",
    "            label = 1\n",
    "\n",
    "        else:\n",
    "            wave_out = wave_speech\n",
    "            label = 0\n",
    "\n",
    "        return wave_out, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:00.869003500Z",
     "start_time": "2023-07-21T10:30:00.638750700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_dataset_train = AudioDataset('./CleanSpeechTrain.csv',\n",
    "                                   './NoiseTrain.csv')\n",
    "\n",
    "audio_dataset_val = AudioDataset('./CleanSpeechVal.csv',\n",
    "                                   './NoiseVal.csv')\n",
    "\n",
    "audio_dataset_test = AudioDataset('./CleanSpeechTest.csv',\n",
    "                                   './NoiseTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:02.467908200Z",
     "start_time": "2023-07-21T10:30:02.417128300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=audio_dataset_train,\n",
    "                          batch_size=100, drop_last=True, num_workers=4)\n",
    "\n",
    "val_loader = DataLoader(dataset=audio_dataset_val,\n",
    "                        batch_size=100, drop_last=True, num_workers=4)\n",
    "\n",
    "test_loader = DataLoader(dataset=audio_dataset_test,\n",
    "                         batch_size=100, drop_last=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "\n",
    "        x_gpu = x.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "\n",
    "        prediction = model(x_gpu).squeeze(1)\n",
    "        correct_samples += torch.sum(prediction.round()==y_gpu)\n",
    "        total_samples += y_gpu.size(0)\n",
    "\n",
    "    return float(correct_samples) / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:05.909594300Z",
     "start_time": "2023-07-21T10:30:05.878809600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss,\n",
    "          optimizer, warmup_scheduler, num_epochs):\n",
    "\n",
    "    wandb.init(\n",
    "        project='Noise-Estimation',\n",
    "        config={'learning_rate': 1e-4,\n",
    "                'model': 'MHAttKWS',\n",
    "                'loss': 'BCEWithLogitsLoss',\n",
    "                'optimizer': 'SGD',\n",
    "                'scheduler': 'CosineAnnealing',\n",
    "                'epochs': 100}\n",
    "    )\n",
    "\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        with tqdm(total=len(train_loader),\n",
    "                  desc=f'Epoch {epoch+1}',\n",
    "                  leave=True) as pb:\n",
    "\n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "                x_gpu = x.to(device)\n",
    "                y_gpu = y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(x_gpu).squeeze(1)\n",
    "\n",
    "                loss_value = loss(prediction, y_gpu.float())\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                correct_samples += torch.sum(prediction.round()==y_gpu)\n",
    "                total_samples += y.size(0)\n",
    "                loss_accum += loss_value\n",
    "\n",
    "                pb.update()\n",
    "                pb.set_description( f'Epoch {epoch+1}:'\n",
    "                                    f' Average epoch loss: {loss_accum / num_batches:.3f}'\n",
    "                                    f' Train accuracy:'\n",
    "                                    f' {correct_samples/total_samples:.2f},'\n",
    "                                    )\n",
    "                num_batches += 1\n",
    "\n",
    "            ave_loss = loss_accum / num_batches\n",
    "            train_accuracy = float(correct_samples) / total_samples\n",
    "            val_accuracy = compute_accuracy(model, val_loader)\n",
    "\n",
    "            if warmup_scheduler:\n",
    "                warmup_scheduler.step()\n",
    "\n",
    "            loss_history.append(float(ave_loss))\n",
    "            train_history.append(train_accuracy)\n",
    "            val_history.append(val_accuracy)\n",
    "\n",
    "            wandb.log({'Epoch': epoch+1, 'loss': ave_loss,\n",
    "                       'train_acc': train_accuracy,\n",
    "                       'val_acc': val_accuracy})\n",
    "\n",
    "            pb.set_description( f'Epoch {epoch+1}:'\n",
    "                                f' Average epoch loss: {ave_loss:.3f}'\n",
    "                                f' Train accuracy: {train_accuracy:.2f},'\n",
    "                                f' Val accuracy: {val_accuracy:.2f}'\n",
    "                                )\n",
    "\n",
    "    wandb.finish()\n",
    "    return loss_history, train_history, val_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MHAttKWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:10.548611100Z",
     "start_time": "2023-07-21T10:30:10.498046600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "from BCResNet import MHAttKWS\n",
    "model_mhat = MHAttKWS(num_classes=1)\n",
    "model_mhat.type(torch.cuda.FloatTensor)\n",
    "model_mhat.to(device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss().type(torch.FloatTensor)\n",
    "\n",
    "optimizer = optim.SGD(model_mhat.parameters(), lr=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:39:56.639791700Z",
     "start_time": "2023-07-21T10:30:11.929000800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/project/wandb/run-20230802_082719-y931qsat</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/darya-dare/Noise-Estimation/runs/y931qsat' target=\"_blank\">valiant-rain-32</a></strong> to <a href='https://wandb.ai/darya-dare/Noise-Estimation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/darya-dare/Noise-Estimation' target=\"_blank\">https://wandb.ai/darya-dare/Noise-Estimation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/darya-dare/Noise-Estimation/runs/y931qsat' target=\"_blank\">https://wandb.ai/darya-dare/Noise-Estimation/runs/y931qsat</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/30 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.52 GiB (GPU 0; 5.93 GiB total capacity; 3.57 GiB already allocated; 1.51 GiB free; 3.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_history, train_history, val_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_mhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, warmup_scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m y_gpu \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 36\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_gpu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss(prediction, y_gpu\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     39\u001b[0m loss_value\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/BCResNet.py:244\u001b[0m, in \u001b[0;36mMHAttKWS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    242\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_extractor(x)\n\u001b[1;32m    243\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 244\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m middle \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    247\u001b[0m mid_feature \u001b[38;5;241m=\u001b[39m x[:, middle, :]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.52 GiB (GPU 0; 5.93 GiB total capacity; 3.57 GiB already allocated; 1.51 GiB free; 3.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train(model_mhat, train_loader,\n",
    "                                                 val_loader, loss,\n",
    "                                                 optimizer, scheduler,\n",
    "                                                 num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### BCResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "from BCResNet import BCResNet\n",
    "model_bcrn = BCResNet(num_labels=1)\n",
    "model_bcrn.type(torch.cuda.FloatTensor)\n",
    "model_bcrn.to(device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(model_bcrn.parameters(),\n",
    "                       lr=1e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_history, train_history, val_history = train(model_bcrn, train_loader,\n",
    "                                                 val_loader, loss,\n",
    "                                                 optimizer, scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "from vggNet import VGGModel\n",
    "\n",
    "model_vgg = VGGModel(1, 'vgg11')\n",
    "model_vgg.to(device)\n",
    "model_vgg.type(torch.cuda.FloatTensor)\n",
    "\n",
    "loss = nn.BCELoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(model_vgg.parameters(), lr=1e-3)\n",
    "cosine_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, verbose=True)\n",
    "warmup_scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=25,\n",
    "                                          after_scheduler=cosine_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_vgg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_history, train_history, val_history \u001b[38;5;241m=\u001b[39m train(\u001b[43mmodel_vgg\u001b[49m, train_loader,\n\u001b[1;32m      2\u001b[0m                                                  val_loader, loss,\n\u001b[1;32m      3\u001b[0m                                                  optimizer, warmup_scheduler,\n\u001b[1;32m      4\u001b[0m                                                  num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_vgg' is not defined"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train(model_vgg, train_loader,\n",
    "                                                 val_loader, loss,\n",
    "                                                 optimizer, warmup_scheduler,\n",
    "                                                 num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrialDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path_noise, eps_value=1e-6,\\\n",
    "                 mel_nframes=300, sample_rate=16000, n_fft=480,\\\n",
    "                 hop_length=160, n_mels=40):\n",
    "\n",
    "        self.noise = pd.read_csv(path_noise)\n",
    "        self.wave_still = torch.empty(1, 40, 300)\n",
    "        self.eps_value = eps_value\n",
    "        self.mel_nframes = mel_nframes\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.mel_spectrogram = T.MelSpectrogram(sample_rate=self.sample_rate,\n",
    "                                                n_fft=self.n_fft,\n",
    "                                                hop_length=self.hop_length,\n",
    "                                                center=True,\n",
    "                                                pad_mode=\"reflect\",\n",
    "                                                power=2.0,\n",
    "                                                norm='slaney',\n",
    "                                                n_mels=self.n_mels)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.noise)\n",
    "\n",
    "    def get_same_shape(self, waveform):\n",
    "\n",
    "        # melsp = torch.log(self.mel_spectrogram(waveform) + self.eps_value)\n",
    "        melsp = self.mel_spectrogram(waveform)\n",
    "        has_mel_nframes = melsp.size(2) if melsp.size(2) < self.mel_nframes\\\n",
    "         else self.mel_nframes\n",
    "\n",
    "        image_tens = torch.full((1, self.n_mels, self.mel_nframes), melsp.min())\n",
    "        image_tens[0, :, :has_mel_nframes] = melsp[:, :, :has_mel_nframes]\n",
    "\n",
    "        return image_tens\n",
    "\n",
    "    def load_item(self, df, idx):\n",
    "\n",
    "        sample_wav_file = df['filename'][idx]\n",
    "        wave, _ = torchaudio.load(sample_wav_file)\n",
    "        wave = wave.float()\n",
    "\n",
    "        wave_melsp = self.get_same_shape(wave)\n",
    "\n",
    "        return wave_melsp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        luck = random.random()\n",
    "        if luck >= 0.5:\n",
    "            wave_out = self.load_item(self.noise, idx)\n",
    "            label = 1\n",
    "\n",
    "        else:\n",
    "            wave_out = torch.fill(self.wave_still, -1)\n",
    "            label = 0\n",
    "\n",
    "        return wave_out, torch.tensor(label).type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial_dataset_train = TrialDataset('./NoiseTrain.csv')\n",
    "\n",
    "trial_dataset_val = TrialDataset('./NoiseVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melspec,label = trial_dataset_train[5]\n",
    "print(label.item())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(melspec.squeeze(0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=trial_dataset_train,\n",
    "                          batch_size=64, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=trial_dataset_val,\n",
    "                        batch_size=64, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_preds_for_bce(prediction, target):\n",
    "#     correct_preds = []\n",
    "    \n",
    "#     for i in range(len(target)):\n",
    "#         if target[i] == 0:\n",
    "#             correct_preds.append(prediction[i][0])\n",
    "#         else:\n",
    "#             correct_preds.append(prediction[i][1])\n",
    "    \n",
    "#     return torch.tensor(correct_preds).type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        \n",
    "        x_gpu = x.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "\n",
    "        prediction = model(x_gpu)\n",
    "        indices = torch.argmax(prediction, 1)\n",
    "        correct_samples += torch.sum(indices==y_gpu)\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    return float(correct_samples) / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_trial(model, train_loader, val_loader, loss,\n",
    "          optimizer, warmup_scheduler, num_epochs):\n",
    "\n",
    "    wandb.init(\n",
    "        project='Silence-Noise',\n",
    "        config={'learning_rate': 1e-3,\n",
    "                'model': 'VGG',\n",
    "                'loss': 'BCELoss',\n",
    "                'optimizer': 'SGD',\n",
    "                'scheduler': 'None',\n",
    "                'epochs': num_epochs}\n",
    "    )\n",
    "\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "        print(f\"Epoch # {epoch+1} - LR: {get_lr(optimizer)}\")\n",
    "        \n",
    "        with tqdm(total=len(train_loader),\n",
    "                  desc=f'Epoch {epoch+1}',\n",
    "                  leave=True) as pb:\n",
    "\n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "                x_gpu = x.to(device)\n",
    "                y_gpu = y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(x_gpu).squeeze(1)\n",
    "                \n",
    "                # preds = get_preds_for_bce(prediction, y_gpu)\n",
    "                # preds.requires_grad_()\n",
    "                # preds_gpu = preds.to(device)\n",
    "                \n",
    "                \n",
    "                # BUG: Considering all other changes, we don't need that\n",
    "                #values, indices = torch.max(prediction, 1)\n",
    "                \n",
    "                # BUG: we put prediction to loss function, not inference results\n",
    "                # loss_value = loss(values, y_gpu.float())\n",
    "                loss_value = loss(prediction, y_gpu.float())\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                correct_samples += torch.sum(prediction.round()==y_gpu)\n",
    "                total_samples += y.size(0)\n",
    "                loss_accum += loss_value\n",
    "\n",
    "                pb.update()\n",
    "                # BUG: Average loss should be loss_accum/num_batches\n",
    "                pb.set_description( f'Epoch {epoch+1}:' \n",
    "                                    f' LR: {get_lr(optimizer)}'\n",
    "                                    f' Average epoch loss: {loss_accum/num_batches:.3f}'\n",
    "                                    f' Train accuracy:'\n",
    "                                    f' {correct_samples/total_samples:.2f},'\n",
    "                                    )\n",
    "                num_batches += 1\n",
    "            \n",
    "            # BUG: was /epoch+1, needs to be /num_batches\n",
    "            # ave_loss = loss_accum / /epoch+1\n",
    "            ave_loss = loss_accum / num_batches\n",
    "            train_accuracy = float(correct_samples) / total_samples\n",
    "            val_accuracy = compute_accuracy(model, val_loader)\n",
    "            \n",
    "            if warmup_scheduler:\n",
    "                warmup_scheduler.step()\n",
    "\n",
    "            loss_history.append(float(ave_loss))\n",
    "            train_history.append(train_accuracy)\n",
    "            val_history.append(val_accuracy)\n",
    "\n",
    "            wandb.log({'Epoch': epoch+1, 'loss': ave_loss,\n",
    "                       'train_acc': train_accuracy,\n",
    "                       'val_acc': val_accuracy})\n",
    "            pb.set_description( f'Epoch {epoch+1}:'\n",
    "                                f' Average epoch loss: {loss_accum/num_batches:.3f}'\n",
    "                                f' Train accuracy: {train_accuracy:.2f},'\n",
    "                                f' Val accuracy: {val_accuracy:.2f}'\n",
    "                                )\n",
    "\n",
    "    wandb.finish()\n",
    "    return loss_history, train_history, val_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BUG: more like a suggestion, but model should be recreated with each run, so I'd put it here\n",
    "# BUG: model should have 1 as first argument, not 2, because essentially we can use 1 output from the model with threshold in case of binary classification in spite of having 2 labels\n",
    "from vggNet import VGGModel\n",
    "model_vgg = VGGModel(1, 'vgg11')\n",
    "model_vgg.to(device)\n",
    "model_vgg.type(torch.cuda.FloatTensor)\n",
    "\n",
    "loss = nn.BCELoss().type(torch.cuda.FloatTensor)\n",
    "\n",
    "optimizer = optim.SGD(model_vgg.parameters(), lr=1e-3)\n",
    "\n",
    "# cosine_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, verbose=True)\n",
    "\n",
    "#warmup_scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=50,\n",
    "#                                          after_scheduler=cosine_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e2vs2gyq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fce475416d487f9eecf80f6aa9eb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.029 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.091581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>val_acc</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>loss</td><td>0.68452</td></tr><tr><td>train_acc</td><td>0.62142</td></tr><tr><td>val_acc</td><td>0.5166</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-butterfly-34</strong> at: <a href='https://wandb.ai/darya-dare/Silence-Noise/runs/e2vs2gyq' target=\"_blank\">https://wandb.ai/darya-dare/Silence-Noise/runs/e2vs2gyq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230801_154651-e2vs2gyq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e2vs2gyq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5644822a166549a8b161224b3010e073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666929225126902, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/project/wandb/run-20230801_154757-7h7n3r7d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/darya-dare/Silence-Noise/runs/7h7n3r7d' target=\"_blank\">floral-glade-35</a></strong> to <a href='https://wandb.ai/darya-dare/Silence-Noise' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/darya-dare/Silence-Noise' target=\"_blank\">https://wandb.ai/darya-dare/Silence-Noise</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/darya-dare/Silence-Noise/runs/7h7n3r7d' target=\"_blank\">https://wandb.ai/darya-dare/Silence-Noise/runs/7h7n3r7d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average epoch loss: 0.682 Train accuracy: 0.62, Val accuracy: 0.50: 100%|| 48/48 [00:15<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 2 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average epoch loss: 0.665 Train accuracy: 0.67, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 3 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average epoch loss: 0.642 Train accuracy: 0.59, Val accuracy: 0.48: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 4 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: Average epoch loss: 0.598 Train accuracy: 0.54, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 5 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: Average epoch loss: 0.527 Train accuracy: 0.51, Val accuracy: 0.48: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 6 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: Average epoch loss: 0.453 Train accuracy: 0.53, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 7 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: Average epoch loss: 0.406 Train accuracy: 0.70, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 8 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: Average epoch loss: 0.366 Train accuracy: 0.91, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 9 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: Average epoch loss: 0.326 Train accuracy: 0.99, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 10 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: Average epoch loss: 0.291 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 11 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: Average epoch loss: 0.263 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 12 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: Average epoch loss: 0.219 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 13 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: Average epoch loss: 0.184 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 14 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: Average epoch loss: 0.146 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 15 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: Average epoch loss: 0.116 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 16 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: Average epoch loss: 0.086 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 17 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: Average epoch loss: 0.066 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 18 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: Average epoch loss: 0.050 Train accuracy: 1.00, Val accuracy: 0.53: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 19 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: Average epoch loss: 0.040 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 20 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: Average epoch loss: 0.034 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 21 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: Average epoch loss: 0.026 Train accuracy: 1.00, Val accuracy: 0.53: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 22 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: Average epoch loss: 0.021 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 23 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: Average epoch loss: 0.018 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 24 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: Average epoch loss: 0.015 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 25 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: Average epoch loss: 0.013 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 26 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: Average epoch loss: 0.011 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 27 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: Average epoch loss: 0.009 Train accuracy: 1.00, Val accuracy: 0.46: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 28 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: Average epoch loss: 0.009 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 29 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: Average epoch loss: 0.008 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 30 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: Average epoch loss: 0.007 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 31 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: Average epoch loss: 0.006 Train accuracy: 1.00, Val accuracy: 0.48: 100%|| 48/48 [00:14<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 32 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: Average epoch loss: 0.006 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 33 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: Average epoch loss: 0.005 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 34 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: Average epoch loss: 0.005 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 35 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: Average epoch loss: 0.004 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 36 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: Average epoch loss: 0.004 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 37 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: Average epoch loss: 0.004 Train accuracy: 1.00, Val accuracy: 0.54: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 38 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 39 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 40 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 41 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 42 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.48: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 43 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.53: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 44 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: Average epoch loss: 0.003 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 45 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.48: 100%|| 48/48 [00:14<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 46 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.47: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 47 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.49: 100%|| 48/48 [00:14<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 48 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.53: 100%|| 48/48 [00:14<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 49 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.50: 100%|| 48/48 [00:14<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50 - LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: Average epoch loss: 0.002 Train accuracy: 1.00, Val accuracy: 0.51: 100%|| 48/48 [00:14<00:00,  3.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4512058985439e8d8d77282b3fb379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>val_acc</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>50</td></tr><tr><td>loss</td><td>0.00186</td></tr><tr><td>train_acc</td><td>1.0</td></tr><tr><td>val_acc</td><td>0.51172</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-glade-35</strong> at: <a href='https://wandb.ai/darya-dare/Silence-Noise/runs/7h7n3r7d' target=\"_blank\">https://wandb.ai/darya-dare/Silence-Noise/runs/7h7n3r7d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230801_154757-7h7n3r7d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train_trial(\n",
    "    model_vgg, train_loader, val_loader, loss, \n",
    "    optimizer, None, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
