{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torchaudio.transforms import AmplitudeToDB, Vol\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T12:18:30.759697600Z",
     "start_time": "2023-07-21T12:18:26.611326600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from BCResNet import MHAttKWS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:29:52.923491800Z",
     "start_time": "2023-07-21T10:29:52.538831100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdarya-dare\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:29:57.808377200Z",
     "start_time": "2023-07-21T10:29:53.438631300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Custom Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path_speech, path_noise, eps_value=1e-6,\\\n",
    "                 mel_nframes=300, sample_rate=16000, n_fft=480,\\\n",
    "                 hop_length=160, n_mels=40):\n",
    "\n",
    "        self.speech = pd.read_csv(path_speech)\n",
    "        self.noise = pd.read_csv(path_noise)\n",
    "        self.eps_value = eps_value\n",
    "        self.mel_nframes = mel_nframes\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.mel_spectrogram = T.MelSpectrogram(sample_rate=self.sample_rate,\n",
    "                                                n_fft=self.n_fft,\n",
    "                                                hop_length=self.hop_length,\n",
    "                                                center=True,\n",
    "                                                pad_mode=\"reflect\",\n",
    "                                                power=2.0,\n",
    "                                                norm='slaney',\n",
    "                                                n_mels=self.n_mels)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.noise)\n",
    "\n",
    "    def get_same_shape(self, waveform, w_type):\n",
    "\n",
    "        melsp = torch.log(self.mel_spectrogram(waveform) + self.eps_value)\n",
    "        has_mel_nframes = melsp.size(2) if melsp.size(2) < self.mel_nframes\\\n",
    "         else self.mel_nframes\n",
    "\n",
    "        image_tens = torch.full((1, self.n_mels, self.mel_nframes), melsp.min())\n",
    "        image_tens[0, :, :has_mel_nframes] = melsp[:, :, :has_mel_nframes]\n",
    "\n",
    "        return image_tens/255\n",
    "\n",
    "    def load_item(self, df, idx, w_type):\n",
    "\n",
    "        sample_wav_file = df['filename'][idx]\n",
    "        wave, _ = torchaudio.load(sample_wav_file)\n",
    "        wave = wave.float()\n",
    "\n",
    "        if w_type==1:\n",
    "            wave_noise = wave.numpy()\n",
    "            wave_noise_no_silence = [float(el) for el in wave_noise[0] if abs(el) >= 0.001]\n",
    "            wave = torch.tensor([wave_noise_no_silence])\n",
    "\n",
    "        wave_melsp = self.get_same_shape(wave, w_type)\n",
    "\n",
    "        return wave_melsp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        wave_speech = self.load_item(self.speech, idx, w_type=0)\n",
    "\n",
    "        luck = random.random()\n",
    "        if luck > 0.5:\n",
    "            wave_noise = self.load_item(self.noise, idx, w_type=1)\n",
    "\n",
    "            wave_out = wave_speech + wave_noise\n",
    "            label = 1\n",
    "\n",
    "        else:\n",
    "            wave_out = wave_speech\n",
    "            label = 0\n",
    "\n",
    "        return wave_out, torch.tensor(label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T12:18:34.545339Z",
     "start_time": "2023-07-21T12:18:34.525573800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "audio_dataset_train = AudioDataset('./CleanSpeechTrain.csv',\n",
    "                                   './NoiseTrain.csv')\n",
    "\n",
    "audio_dataset_val = AudioDataset('./CleanSpeechVal.csv',\n",
    "                                   './NoiseVal.csv')\n",
    "\n",
    "audio_dataset_test = AudioDataset('./CleanSpeechTest.csv',\n",
    "                                   './NoiseTest.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:00.869003500Z",
     "start_time": "2023-07-21T10:30:00.638750700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=audio_dataset_train,\n",
    "                          batch_size=50, drop_last=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=audio_dataset_val,\n",
    "                        batch_size=50, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=audio_dataset_test,\n",
    "                         batch_size=50, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:02.467908200Z",
     "start_time": "2023-07-21T10:30:02.417128300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss,\n",
    "          optimizer, scheduler, num_epochs):\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"my-project\",\n",
    "\n",
    "        config={\"learning_rate\": 1e-2,\n",
    "                \"model\": \"MHAttKWS\",\n",
    "                'loss': 'BCEWithLogitsLoss',\n",
    "                \"optimizer\": \"SGD\",\n",
    "                'scheduler': 'StepLR',\n",
    "                \"epochs\": 5}\n",
    "    )\n",
    "\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with tqdm(total=len(train_loader),\n",
    "                  desc=f'Epoch {epoch+1}',\n",
    "                  leave=True) as pb:\n",
    "\n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "                x_gpu = x.to(device)\n",
    "                y_gpu = y.to(device)\n",
    "\n",
    "                prediction = model(x_gpu)\n",
    "                value, indices = torch.max(prediction, 1)\n",
    "\n",
    "                loss_value = loss(value, y_gpu.float())\n",
    "                optimizer.zero_grad()\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                correct_samples += torch.sum(indices==y_gpu)\n",
    "                total_samples += y.size(0)\n",
    "                loss_accum += loss_value\n",
    "\n",
    "                pb.update()\n",
    "                pb.set_description( f'Epoch {epoch+1}:'\n",
    "                                    f' Average loss: {loss_value:.3f},'\n",
    "                                    f' Train accuracy:'\n",
    "                                    f' {correct_samples/total_samples:.2f},'\n",
    "                                    )\n",
    "\n",
    "            ave_loss = loss_accum / epoch+1\n",
    "            train_accuracy = float(correct_samples) / total_samples\n",
    "            val_accuracy = compute_accuracy(model, val_loader)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            loss_history.append(float(ave_loss))\n",
    "            train_history.append(train_accuracy)\n",
    "            val_history.append(val_accuracy)\n",
    "\n",
    "            wandb.log({'Epoch': epoch+1, 'loss': ave_loss,\n",
    "                       'train_acc': train_accuracy,\n",
    "                       'val_acc': val_accuracy})\n",
    "\n",
    "            pb.set_description( f'Epoch {epoch+1}:'\n",
    "                                f' Average loss: {ave_loss:.3f},'\n",
    "                                f' Train accuracy: {train_accuracy:.2f},'\n",
    "                                f' Val accuracy: {val_accuracy:.2f}'\n",
    "                                )\n",
    "\n",
    "    wandb.finish()\n",
    "    return loss_history, train_history, val_history\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "\n",
    "        x_gpu = x.to(device)\n",
    "        y_gpu = y.to(device)\n",
    "\n",
    "        prediction = model(x_gpu)\n",
    "        indices = torch.argmax(prediction, 1)\n",
    "        correct_samples += torch.sum(indices==y_gpu)\n",
    "        total_samples += y_gpu.size(0)\n",
    "\n",
    "    return float(correct_samples) / total_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:05.909594300Z",
     "start_time": "2023-07-21T10:30:05.878809600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MHAttKWS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "MHAttKWS(\n  (cnn_extractor): Sequential(\n    (0): Conv2d(1, 10, kernel_size=(5, 1), stride=(1, 1))\n    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(10, 1, kernel_size=(5, 1), stride=(1, 1))\n    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  )\n  (rnn): LSTM(1, 128, num_layers=2, batch_first=True, bidirectional=True)\n  (q_emb): Linear(in_features=256, out_features=1024, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (fc): Sequential(\n    (0): Linear(in_features=1024, out_features=64, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=64, out_features=32, bias=True)\n    (3): Linear(in_features=32, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mhat = MHAttKWS(num_classes=2)\n",
    "model_mhat.type(torch.FloatTensor)\n",
    "model_mhat.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:08.149914400Z",
     "start_time": "2023-07-21T10:30:08.089023900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss().type(torch.FloatTensor)\n",
    "\n",
    "optimizer = optim.SGD(model_mhat.parameters(),\n",
    "                       lr=1e-2,\n",
    "                       weight_decay=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:30:10.548611100Z",
     "start_time": "2023-07-21T10:30:10.498046600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333266395, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcb402a2359a48bc873fca018439ddcb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\ml\\audio\\wandb\\run-20230721_133012-wth6iltx</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/darya-dare/my-project/runs/wth6iltx' target=\"_blank\">breezy-mountain-33</a></strong> to <a href='https://wandb.ai/darya-dare/my-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/darya-dare/my-project' target=\"_blank\">https://wandb.ai/darya-dare/my-project</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/darya-dare/my-project/runs/wth6iltx' target=\"_blank\">https://wandb.ai/darya-dare/my-project/runs/wth6iltx</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average loss: inf, Train accuracy: 0.48, Val accuracy: 0.50: 100%|██████████| 61/61 [09:13<00:00,  9.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65601e484be6470690cdf1f03f815ba1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>loss</td><td>inf</td></tr><tr><td>train_acc</td><td>0.48</td></tr><tr><td>val_acc</td><td>0.502</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">breezy-mountain-33</strong> at: <a href='https://wandb.ai/darya-dare/my-project/runs/wth6iltx' target=\"_blank\">https://wandb.ai/darya-dare/my-project/runs/wth6iltx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230721_133012-wth6iltx\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train(model_mhat, train_loader,\n",
    "                                                 val_loader, loss,\n",
    "                                                 optimizer, scheduler,\n",
    "                                                 num_epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:39:56.639791700Z",
     "start_time": "2023-07-21T10:30:11.929000800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
